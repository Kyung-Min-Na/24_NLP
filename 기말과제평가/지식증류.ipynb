{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6f7165-04c9-45ec-8550-9dd4c1f11fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24123d0-c526-4571-8bd3-98fd231dc7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TextClassificationPipeline\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69026e44-1fd6-4476-a1ac-b66b35538885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1491: FutureWarning: The repository for searle-j/kote contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/searle-j/kote\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"searle-j/kote_for_easygoing_people\"\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 데이터셋 로드\n",
    "dataset = load_dataset(\"searle-j/kote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66199ffc-eb89-40e5-a6c9-9a4ead413a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe = TextClassificationPipeline(\n",
    "    model=teacher_model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1,  # gpu number, -1 if cpu used\n",
    "    return_all_scores=True,\n",
    "    function_to_apply='sigmoid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80216a30-41f0-419a-bf74-d351c2712915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(examples):\n",
    "    inputs = tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
    "    labels = torch.zeros((len(examples['labels']), teacher_model.config.num_labels))\n",
    "    for i, label_list in enumerate(examples['labels']):\n",
    "        for label in label_list:\n",
    "            labels[i][label] = 1\n",
    "    inputs['labels'] = labels\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_and_encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23228a5a-0399-4e23-8124-fe577b3e02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터셋 클래스 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 여기서 필요한 키만 선택하여 텐서로 변환합니다.\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9850d379-0c9c-4f98-bba2-1f447cf3df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensors(dataset):\n",
    "    return {\n",
    "        'input_ids': torch.tensor(dataset['input_ids']),\n",
    "        'attention_mask': torch.tensor(dataset['attention_mask']),\n",
    "        'labels': torch.tensor(dataset['labels'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9209d706-5d43-46cb-bfcc-310d9e267ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(convert_to_tensors(tokenized_dataset['train']))\n",
    "val_dataset = CustomDataset(convert_to_tensors(tokenized_dataset['validation']))\n",
    "test_dataset = CustomDataset(convert_to_tensors(tokenized_dataset['test']))\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0288c9f5-259d-49d0-b47b-b5a3b9f3cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 학생 모델 정의 (LSTM 기반)\n",
    "class LSTMStudentModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
    "        super(LSTMStudentModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embedded = self.embedding(input_ids)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        output = self.fc(lstm_out)\n",
    "        return self.sigmoid(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6bdc436-c405-496c-aa89-7f299351e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1493dde-d790-4598-9ef6-dd4565b29a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = tokenizer.vocab_size\n",
    "hidden_dim = 256\n",
    "output_dim = teacher_model.config.num_labels\n",
    "n_layers = 2\n",
    "student_model = LSTMStudentModel(input_dim, hidden_dim, output_dim, n_layers).to(device)\n",
    "\n",
    "# 옵티마이저 및 손실 함수 설정\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee8f4cd-6251-41aa-b8ca-bfbf1426b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_loss(student_logits, teacher_logits, temperature):\n",
    "    teacher_probs = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    student_log_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)\n",
    "    return nn.functional.kl_div(student_log_probs, teacher_probs, reduction='batchmean') * (temperature ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63b09696-bdfd-46cc-ad89-d5bb0a9151dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, teacher_model, dataloader, optimizer, criterion, device, temperature=2.0, alpha=0.5):\n",
    "    model.train()\n",
    "    teacher_model.eval()\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].float().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            teacher_logits = teacher_outputs.logits\n",
    "\n",
    "        student_outputs = model(input_ids)\n",
    "        student_loss = criterion(student_outputs, labels)\n",
    "        distill_loss = distillation_loss(student_outputs, teacher_logits, temperature)\n",
    "        loss = alpha * student_loss + (1 - alpha) * distill_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4916eeeb-3c94-4673-a522-dfa1ca475f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].float().to(device)\n",
    "            outputs = model(input_ids)\n",
    "            preds = (outputs > 0.3).float()\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    return f1_score(all_labels, all_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adbc00ca-5776-487e-b90e-133793c705dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Training: 100%|██████████| 2500/2500 [06:39<00:00,  6.25it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 95.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Validation Macro F1: 0.1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Training: 100%|██████████| 2500/2500 [06:40<00:00,  6.24it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 97.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Validation Macro F1: 0.1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Training: 100%|██████████| 2500/2500 [06:40<00:00,  6.25it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 94.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Validation Macro F1: 0.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Training: 100%|██████████| 2500/2500 [06:40<00:00,  6.25it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 95.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Validation Macro F1: 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Training: 100%|██████████| 2500/2500 [06:40<00:00,  6.24it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 97.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Validation Macro F1: 0.1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Training: 100%|██████████| 2500/2500 [06:41<00:00,  6.23it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 95.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Validation Macro F1: 0.1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Training: 100%|██████████| 2500/2500 [06:40<00:00,  6.23it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 88.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Validation Macro F1: 0.1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Training: 100%|██████████| 2500/2500 [06:41<00:00,  6.23it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 91.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Validation Macro F1: 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Training: 100%|██████████| 2500/2500 [06:40<00:00,  6.23it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 94.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Validation Macro F1: 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Training: 100%|██████████| 2500/2500 [06:41<00:00,  6.23it/s]\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 93.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Validation Macro F1: 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train(student_model, teacher_model, train_loader, optimizer, criterion, device)\n",
    "    val_f1 = evaluate(student_model, val_loader, device)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Macro F1: {val_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98a244ac-1d36-4a74-ba63-a2120779adbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 98.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Macro F1: 0.1500\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트 평가\n",
    "test_f1 = evaluate(student_model, test_loader, device)\n",
    "print(f'Test Macro F1: {test_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b213edb9-c089-4e58-bc6e-41f16887adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75475782-1dea-4bab-8bb7-d73750defc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_pipe = TextClassificationPipeline(\n",
    "    model=teacher_model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1,  # gpu number, -1 if cpu used\n",
    "    return_all_scores=True,\n",
    "    function_to_apply='sigmoid'\n",
    ")\n",
    "\n",
    "# 학생 모델에 대한 파이프라인 생성\n",
    "def student_predict(model, tokenizer, text, device):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs['input_ids'])\n",
    "    return outputs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23f17c8b-3be3-4cc7-95f4-4547b46357d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"\"\"재미있어요! 재미는 확실히 있는데 뭐랄까... 너무 정신 없달까...ㅋㅋ\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1bc686a-d67f-461c-9cc7-0ab0da6002ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선생님 모델 추론 시간 측정\n",
    "start_time = time.time()\n",
    "teacher_output = teacher_pipe(test_input)[0]\n",
    "teacher_time = time.time() - start_time\n",
    "\n",
    "# 학생 모델 추론 시간 측정\n",
    "start_time = time.time()\n",
    "student_output = student_predict(student_model, tokenizer, test_input, device)\n",
    "student_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94e763fd-daf5-4ae5-9f1c-f5f51443c42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Model Inference Time: 0.019019 seconds\n",
      "Student Model Inference Time: 0.009911 seconds\n",
      "\n",
      "Teacher Model Output:\n",
      "{'label': '안타까움/실망', 'score': 0.7095019817352295}\n",
      "{'label': '즐거움/신남', 'score': 0.8421469330787659}\n",
      "{'label': '당황/난처', 'score': 0.4448468089103699}\n",
      "{'label': '행복', 'score': 0.46983569860458374}\n",
      "{'label': '기쁨', 'score': 0.7035971879959106}\n",
      "\n",
      "Student Model Output:\n",
      "{'label': 'label_0', 'score': 0.83225137}\n",
      "{'label': 'label_2', 'score': 0.5983677}\n",
      "{'label': 'label_6', 'score': 0.5548921}\n",
      "{'label': 'label_8', 'score': 0.5338372}\n",
      "{'label': 'label_10', 'score': 0.7826703}\n",
      "{'label': 'label_15', 'score': 0.40680328}\n",
      "{'label': 'label_22', 'score': 0.67906785}\n",
      "{'label': 'label_23', 'score': 0.6680849}\n",
      "{'label': 'label_28', 'score': 0.65936023}\n",
      "{'label': 'label_42', 'score': 0.54550856}\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(\"Teacher Model Inference Time: {:.6f} seconds\".format(teacher_time))\n",
    "print(\"Student Model Inference Time: {:.6f} seconds\".format(student_time))\n",
    "\n",
    "print(\"\\nTeacher Model Output:\")\n",
    "for output in teacher_output:\n",
    "    if output[\"score\"] > 0.4:\n",
    "        print(output)\n",
    "\n",
    "print(\"\\nStudent Model Output:\")\n",
    "for idx, score in enumerate(student_output[0]):\n",
    "    if score > 0.4:\n",
    "        print({'label': f'label_{idx}', 'score': score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d46edef-d58d-4d4e-8be1-3a3e62e299b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teacher Model Structure:\n",
      "ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(50135, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): GELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=44, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Student Model Structure:\n",
      "LSTMStudentModel(\n",
      "  (embedding): Embedding(50135, 256)\n",
      "  (lstm): LSTM(256, 256, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=44, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTeacher Model Structure:\")\n",
    "print(teacher_model)\n",
    "\n",
    "print(\"\\nStudent Model Structure:\")\n",
    "print(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d8e7cbb-910b-406d-980a-72b7535bd2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acc(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].float().to(device)\n",
    "            outputs = model(input_ids)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    return f1_score(all_labels, all_preds, average='macro'), accuracy_score(all_labels, (all_preds > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a083dce9-c998-4a5e-b7ba-b84eca0ed5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcccf369-b105-49a8-812b-ff3d23e344de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 100.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher - Test Macro F1: 0.1014, Test Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]/tmp/ipykernel_2798/720612499.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask', 'labels']}\n",
      "Evaluating: 100%|██████████| 313/313 [00:03<00:00, 100.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student - Test Macro F1: 0.1014, Test Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "test_f1, test_accuracy = evaluate_acc(student_model, test_loader, device)\n",
    "print(f'Teacher - Test Macro F1: {test_f1:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "test_f1, test_accuracy = evaluate_acc(student_model, test_loader, device)\n",
    "print(f'Student - Test Macro F1: {test_f1:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a30cf-123d-4e6f-9d43-ba933c368443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
